{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2b65e1b",
        "outputId": "0a3b0e5a-d612-4b4a-c2b8-7a4321458c75"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting torch_geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch_geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch_geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch_geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch_geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch_geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch_geometric\n",
            "Successfully installed torch_geometric-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install torch_geometric"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w6KkQLUoHmyn",
        "outputId": "d12d2ee8-7c01-48c1-d430-251ab6b24dc3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "PyTorch Version: 2.9.0+cu126\n",
            "PyG Version: 2.7.0\n"
          ]
        }
      ],
      "source": [
        "# ==============================================================================\n",
        "# PROJETO: Alocação de Recursos de Workflow com GNNs e PyTorch\n",
        "#\n",
        "# Abordagem: Modelo 2 (Não-Supervisionado com GNN Alocadora e GNN Avaliadora)\n",
        "# Baseado em: \"Unsupervised Resource Allocation with GNNs\" (Cranmer et al., 2021)\n",
        "#\n",
        "# Este arquivo é um notebook Jupyter em formato .py.\n",
        "# Você pode executá-lo célula por célula em um ambiente Jupyter (VS Code, Lab).\n",
        "# ==============================================================================\n",
        "\n",
        "# %%\n",
        "# ==============================================================================\n",
        "# CÉLULA 1: Instalação e Configuração de Imports\n",
        "# ==============================================================================\n",
        "#\n",
        "# !pip install torch torch-geometric networkx matplotlib numpy\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Imports do PyTorch Geometric (PyG)\n",
        "import torch_geometric\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import GATConv, HeteroConv, global_mean_pool\n",
        "\n",
        "# Outras bibliotecas\n",
        "import networkx as nx\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from collections import deque\n",
        "import math\n",
        "\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"PyG Version: {torch_geometric.__version__}\")\n",
        "\n",
        "# Configurações\n",
        "torch.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 510
        },
        "id": "axKJhlS6Ht9R",
        "outputId": "3e504e17-e50a-4b61-f3bf-34f491c0804e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Número total de nós no DAG (incluindo source/sink): 12\n",
            "Shape da Matriz de Tempos: (12, 3)\n",
            "Shape da Matriz de Custos: (12, 3)\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 600x400 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# %%\n",
        "# ==============================================================================\n",
        "# CÉLULA 2: Geração de Dados Sintéticos (Problema)\n",
        "# ==============================================================================\n",
        "#\n",
        "# Precisamos de duas coisas para um \"problema\":\n",
        "# 1. Um workflow (DAG) de tarefas.\n",
        "# 2. Uma matriz de custo/tempo (Tarefas x VMs).\n",
        "#\n",
        "\n",
        "def generate_workflow_dag(num_tasks: int, max_deps: int = 3, density: float = 0.2):\n",
        "    \"\"\"\n",
        "    Gera um DAG de workflow aleatório usando NetworkX.\n",
        "    Garante que é um DAG ao adicionar arestas apenas \"para frente\".\n",
        "    \"\"\"\n",
        "    G = nx.DiGraph()\n",
        "    nodes = list(range(num_tasks))\n",
        "    random.shuffle(nodes) # Garante uma ordem topológica aleatória\n",
        "\n",
        "    for i in range(1, num_tasks):\n",
        "        node_i = nodes[i]\n",
        "        possible_predecessors = nodes[:i]\n",
        "\n",
        "        # Garante que cada tarefa (exceto a primeira) tenha pelo menos um predecessor\n",
        "        # para criar um grafo mais conectado, mas isso é opcional.\n",
        "        # Aqui, vamos focar na densidade.\n",
        "\n",
        "        num_deps = 0\n",
        "        for j in range(len(possible_predecessors)):\n",
        "            if num_deps >= max_deps:\n",
        "                break\n",
        "            if random.random() < density:\n",
        "                node_j = possible_predecessors[j]\n",
        "                G.add_edge(node_j, node_i) # Aresta vai do predecessor para o sucessor\n",
        "                num_deps += 1\n",
        "\n",
        "    # Garante que o grafo é conectado (opcional, mas bom)\n",
        "    # Vamos simplificar e assumir que a densidade cuida disso por enquanto.\n",
        "\n",
        "    # Adiciona um nó \"source\" e \"sink\" para garantir início e fim únicos\n",
        "    source = \"source\"\n",
        "    sink = \"sink\"\n",
        "    G.add_node(source)\n",
        "    G.add_node(sink)\n",
        "\n",
        "    roots = [node for node, in_degree in G.in_degree() if in_degree == 0 and node not in [source, sink]]\n",
        "    leaves = [node for node, out_degree in G.out_degree() if out_degree == 0 and node not in [source, sink]]\n",
        "\n",
        "    for root in roots:\n",
        "        G.add_edge(source, root)\n",
        "\n",
        "    for leaf in leaves:\n",
        "        G.add_edge(leaf, sink)\n",
        "\n",
        "    # Renomeia nós para inteiros para facilitar o PyG\n",
        "    G = nx.convert_node_labels_to_integers(G, first_label=0)\n",
        "\n",
        "    return G\n",
        "\n",
        "def generate_cost_time_matrix(num_tasks: int, num_vms: int):\n",
        "    \"\"\"\n",
        "    Gera matrizes aleatórias de tempo e custo.\n",
        "    \"\"\"\n",
        "    # Tempo: e.g., de 10 a 100 unidades\n",
        "    times = np.random.randint(10, 101, size=(num_tasks, num_vms)).astype(np.float32)\n",
        "    # Custo: e.g., de 1 a 20 unidades\n",
        "    costs = np.random.randint(1, 21, size=(num_tasks, num_vms)).astype(np.float32)\n",
        "    return times, costs\n",
        "\n",
        "# --- Teste das funções ---\n",
        "NUM_TASKS_TEST = 10\n",
        "NUM_VMS_TEST = 3\n",
        "\n",
        "test_dag = generate_workflow_dag(NUM_TASKS_TEST)\n",
        "# Note: O DAG terá NUM_TASKS_TEST + 2 nós (source, sink)\n",
        "num_nodes_total = test_dag.number_of_nodes()\n",
        "print(f\"Número total de nós no DAG (incluindo source/sink): {num_nodes_total}\")\n",
        "\n",
        "test_times, test_costs = generate_cost_time_matrix(num_nodes_total, NUM_VMS_TEST)\n",
        "print(f\"Shape da Matriz de Tempos: {test_times.shape}\")\n",
        "print(f\"Shape da Matriz de Custos: {test_costs.shape}\")\n",
        "\n",
        "# Visualização do DAG\n",
        "plt.figure(figsize=(6, 4))\n",
        "pos = nx.spring_layout(test_dag)\n",
        "nx.draw(test_dag, pos, with_labels=True, node_color='lightblue', font_weight='bold')\n",
        "plt.title(\"Exemplo de DAG de Workflow\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hboJ-gd4H5IT",
        "outputId": "c4fcd3e1-bc09-4268-814e-fcc5284000d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Simulador (Alocação Aleatória):\n",
            "  - Makespan (C_max): 206.00\n",
            "  - Custo Total (C_total): 104.00\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "# ==============================================================================\n",
        "# CÉLULA 3: O Simulador (Ground Truth)\n",
        "# ==============================================================================\n",
        "#\n",
        "# Esta é uma função crucial. Ela NÃO é uma GNN.\n",
        "# É um simulador que calcula o Makespan (C_max) e Custo Total (C_total)\n",
        "# para uma DADA alocação.\n",
        "# Usaremos isso para treinar a GNN_Aval.\n",
        "#\n",
        "\n",
        "def calculate_metrics(dag: nx.DiGraph,\n",
        "                      allocations: dict,\n",
        "                      time_matrix: np.ndarray,\n",
        "                      cost_matrix: np.ndarray):\n",
        "    \"\"\"\n",
        "    Calcula o makespan (C_max) e o custo total (C_total) para uma alocação.\n",
        "\n",
        "    Args:\n",
        "        dag: O grafo do workflow (NetworkX).\n",
        "        allocations: Dicionário {node_id: vm_id}.\n",
        "        time_matrix: Matriz (num_tasks, num_vms) de tempos.\n",
        "        cost_matrix: Matriz (num_tasks, num_vms) de custos.\n",
        "    \"\"\"\n",
        "\n",
        "    # Garante que o grafo é um DAG\n",
        "    if not nx.is_directed_acyclic_graph(dag):\n",
        "        raise ValueError(\"O grafo não é um DAG!\")\n",
        "\n",
        "    try:\n",
        "        topo_sort = list(nx.topological_sort(dag))\n",
        "    except nx.NetworkXUnfeasible:\n",
        "        # Se o grafo tiver ciclos (não deveria), isso falhará.\n",
        "        print(\"Erro: Grafo contém ciclos.\")\n",
        "        return float('inf'), float('inf')\n",
        "\n",
        "    finish_times = {}\n",
        "    total_cost = 0.0\n",
        "\n",
        "    for node in topo_sort:\n",
        "        # Obter tempos de término dos predecessores\n",
        "        pred_finish_times = [finish_times.get(pred, 0) for pred in dag.predecessors(node)]\n",
        "\n",
        "        start_time = max(pred_finish_times) if pred_finish_times else 0\n",
        "\n",
        "        # Obter VM alocada\n",
        "        vm_id = allocations.get(node) # e.g., {0: 1, 1: 0, 2: 1, ...}\n",
        "\n",
        "        if vm_id is None:\n",
        "            # Nó não foi alocado? Isso é um erro.\n",
        "            # Para nós 'source' e 'sink', o tempo/custo é 0.\n",
        "            if node in [topo_sort[0], topo_sort[-1]]: # Assumindo source=0, sink=último\n",
        "                 exec_time = 0.0\n",
        "                 exec_cost = 0.0\n",
        "            else:\n",
        "                 raise ValueError(f\"Nó {node} não encontrado nas alocações.\")\n",
        "        else:\n",
        "            exec_time = time_matrix[node, vm_id]\n",
        "            exec_cost = cost_matrix[node, vm_id]\n",
        "\n",
        "        finish_times[node] = start_time + exec_time\n",
        "        total_cost += exec_cost\n",
        "\n",
        "    makespan = finish_times[topo_sort[-1]] # Makespan é o tempo de término do nó 'sink'\n",
        "\n",
        "    return makespan, total_cost\n",
        "\n",
        "# --- Heurísticas para o pré-treino da GNN_Aval ---\n",
        "def heuristic_fastest(dag, time_m):\n",
        "    alloc_dict = {}\n",
        "    for node_id in dag.nodes():\n",
        "        vm_id = np.argmin(time_m[node_id])\n",
        "        alloc_dict[node_id] = vm_id\n",
        "    return alloc_dict\n",
        "\n",
        "def heuristic_cheapest(dag, cost_m):\n",
        "    alloc_dict = {}\n",
        "    for node_id in dag.nodes():\n",
        "        vm_id = np.argmin(cost_m[node_id])\n",
        "        alloc_dict[node_id] = vm_id\n",
        "    return alloc_dict\n",
        "\n",
        "# --- Teste do Simulador ---\n",
        "# Cria uma alocação aleatória\n",
        "num_nodes_total = test_dag.number_of_nodes()\n",
        "random_alloc = {node_id: random.randint(0, NUM_VMS_TEST - 1) for node_id in test_dag.nodes()}\n",
        "\n",
        "# Trata source/sink\n",
        "source_node = list(nx.topological_sort(test_dag))[0]\n",
        "sink_node = list(nx.topological_sort(test_dag))[-1]\n",
        "random_alloc[source_node] = 0 # Não importa, custo/tempo será 0\n",
        "random_alloc[sink_node] = 0\n",
        "\n",
        "# Corrige matrizes para terem custo/tempo 0 para source/sink\n",
        "test_times[source_node, :] = 0\n",
        "test_times[sink_node, :] = 0\n",
        "test_costs[source_node, :] = 0\n",
        "test_costs[sink_node, :] = 0\n",
        "\n",
        "\n",
        "makespan, total_cost = calculate_metrics(test_dag, random_alloc, test_times, test_costs)\n",
        "print(f\"Simulador (Alocação Aleatória):\")\n",
        "print(f\"  - Makespan (C_max): {makespan:.2f}\")\n",
        "print(f\"  - Custo Total (C_total): {total_cost:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uyOrVb01IA4U",
        "outputId": "794219e5-daa1-4f18-a1ea-e8d64e6194a3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Objeto PyG HeteroData:\n",
            "HeteroData(\n",
            "  task={ x=[12, 6] },\n",
            "  vm={ x=[3, 4] },\n",
            "  (task, depends_on, task)={ edge_index=[2, 17] },\n",
            "  (task, can_run_on, vm)={\n",
            "    edge_index=[2, 36],\n",
            "    edge_attr=[36, 2],\n",
            "  },\n",
            "  (vm, rev_can_run_on, task)={\n",
            "    edge_index=[2, 36],\n",
            "    edge_attr=[36, 2],\n",
            "  },\n",
            "  (task, rev_depends_on, task)={ edge_index=[2, 17] }\n",
            ")\n",
            "\n",
            "Tipos de Nós: ['task', 'vm']\n",
            "Tipos de Arestas: [('task', 'depends_on', 'task'), ('task', 'can_run_on', 'vm'), ('vm', 'rev_can_run_on', 'task'), ('task', 'rev_depends_on', 'task')]\n",
            "Arestas 'depends_on': torch.Size([2, 17])\n",
            "Arestas 'can_run_on': torch.Size([2, 36])\n",
            "Atributos 'can_run_on': torch.Size([36, 2])\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "# ==============================================================================\n",
        "# CÉLULA 4: Conversão para Grafo Heterogêneo (PyG)\n",
        "# ==============================================================================\n",
        "#\n",
        "# Esta é a representação de dados que as GNNs irão consumir.\n",
        "# Vamos usar a estrutura HeteroData do PyG.\n",
        "#\n",
        "# Tipos de Nós:\n",
        "# - 'task': Tarefas do workflow (incluindo source/sink)\n",
        "# - 'vm': Máquinas Virtuais\n",
        "#\n",
        "# Tipos de Arestas:\n",
        "# - ('task', 'depends_on', 'task'): Arestas do DAG\n",
        "# - ('task', 'can_run_on', 'vm'): Arestas de alocação (grafo bipartido)\n",
        "#\n",
        "\n",
        "def create_pyg_data(dag: nx.DiGraph,\n",
        "                      time_matrix: np.ndarray,\n",
        "                      cost_matrix: np.ndarray):\n",
        "    \"\"\"\n",
        "    Cria um objeto HeteroData do PyG para um problema.\n",
        "    \"\"\"\n",
        "    data = HeteroData()\n",
        "\n",
        "    num_tasks = dag.number_of_nodes()\n",
        "    num_vms = time_matrix.shape[1]\n",
        "\n",
        "    # --- Nós ---\n",
        "    # MELHORIA: Usar features reais para os nós 'task', em vez de zeros.\n",
        "    # Essas features dão contexto sobre a \"dificuldade\" da tarefa.\n",
        "    time_m = time_matrix.copy()\n",
        "    cost_m = cost_matrix.copy()\n",
        "\n",
        "    # Evitar divisão por zero se houver apenas 1 VM\n",
        "    if num_vms > 1:\n",
        "        time_mean = time_m.mean(axis=1, keepdims=True)\n",
        "        time_std = time_m.std(axis=1, keepdims=True)\n",
        "        cost_mean = cost_m.mean(axis=1, keepdims=True)\n",
        "        cost_std = cost_m.std(axis=1, keepdims=True)\n",
        "    else:\n",
        "        time_mean = time_m\n",
        "        time_std = np.zeros_like(time_m)\n",
        "        cost_mean = cost_m\n",
        "        cost_std = np.zeros_like(cost_m)\n",
        "\n",
        "    time_min = time_m.min(axis=1, keepdims=True)\n",
        "    cost_min = cost_m.min(axis=1, keepdims=True)\n",
        "\n",
        "    # 6 features por tarefa\n",
        "    task_features = np.concatenate([\n",
        "        time_mean, time_std, time_min,\n",
        "        cost_mean, cost_std, cost_min\n",
        "    ], axis=1).astype(np.float32)\n",
        "\n",
        "    # Normalizar as features\n",
        "    task_features = (task_features - task_features.mean(axis=0)) / (task_features.std(axis=0) + 1e-6)\n",
        "\n",
        "    data['task'].x = torch.from_numpy(task_features)\n",
        "\n",
        "    # Características iniciais dos nós 'vm' (ainda podem ser zeros)\n",
        "    data['vm'].x = torch.zeros((num_vms, 4)) # Embedding inicial de 4 dimensões\n",
        "\n",
        "    # --- Arestas de Dependência ('task' -> 'task') ---\n",
        "    edge_list = list(dag.edges()) # Lista de tuplas (u, v)\n",
        "    if edge_list:\n",
        "        edge_index_deps = torch.tensor(edge_list, dtype=torch.long).t().contiguous()\n",
        "    else:\n",
        "        edge_index_deps = torch.empty((2, 0), dtype=torch.long)\n",
        "    data['task', 'depends_on', 'task'].edge_index = edge_index_deps\n",
        "\n",
        "    # --- Arestas de Alocação ('task' -> 'vm') ---\n",
        "    # Grafo bipartido completo: toda tarefa pode rodar em toda VM\n",
        "    task_indices = torch.arange(num_tasks).repeat_interleave(num_vms)\n",
        "    vm_indices = torch.arange(num_vms).repeat(num_tasks)\n",
        "    edge_index_alloc = torch.stack([task_indices, vm_indices], dim=0)\n",
        "\n",
        "    data['task', 'can_run_on', 'vm'].edge_index = edge_index_alloc\n",
        "\n",
        "    # --- Atributos das Arestas de Alocação ---\n",
        "    # As características mais importantes! (Tempo e Custo)\n",
        "    # Precisamos achatar as matrizes na ordem correta\n",
        "    edge_attr_time = torch.from_numpy(time_matrix).float().reshape(-1, 1)\n",
        "    edge_attr_cost = torch.from_numpy(cost_matrix).float().reshape(-1, 1)\n",
        "\n",
        "    # Normalização dos atributos (crucial para GNNs)\n",
        "    edge_attr_time = (edge_attr_time - edge_attr_time.mean()) / (edge_attr_time.std() + 1e-6)\n",
        "    edge_attr_cost = (edge_attr_cost - edge_attr_cost.mean()) / (edge_attr_cost.std() + 1e-6)\n",
        "\n",
        "    data['task', 'can_run_on', 'vm'].edge_attr = torch.cat([edge_attr_time, edge_attr_cost], dim=1)\n",
        "\n",
        "    # --- Arestas Reversas (para agregação de mensagens) ---\n",
        "    # PyG HeteroConv precisa que arestas reversas sejam definidas\n",
        "    data['vm', 'rev_can_run_on', 'task'].edge_index = edge_index_alloc.flip(0)\n",
        "    data['vm', 'rev_can_run_on', 'task'].edge_attr = data['task', 'can_run_on', 'vm'].edge_attr\n",
        "\n",
        "    data['task', 'rev_depends_on', 'task'].edge_index = edge_index_deps.flip(0)\n",
        "\n",
        "    return data\n",
        "\n",
        "# --- Teste da Conversão ---\n",
        "pyg_data = create_pyg_data(test_dag, test_times, test_costs)\n",
        "print(\"\\nObjeto PyG HeteroData:\")\n",
        "print(pyg_data)\n",
        "\n",
        "# Validar a estrutura\n",
        "print(f\"\\nTipos de Nós: {pyg_data.node_types}\")\n",
        "print(f\"Tipos de Arestas: {pyg_data.edge_types}\")\n",
        "print(f\"Arestas 'depends_on': {pyg_data['task', 'depends_on', 'task'].edge_index.shape}\")\n",
        "print(f\"Arestas 'can_run_on': {pyg_data['task', 'can_run_on', 'vm'].edge_index.shape}\")\n",
        "print(f\"Atributos 'can_run_on': {pyg_data['task', 'can_run_on', 'vm'].edge_attr.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qk61tusmIKgR",
        "outputId": "c30eca67-e40a-4283-b85e-150a5b5a3f81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Estrutura GNN_Aval:\n",
            "GNN_Aval(\n",
            "  (task_emb): Linear(in_features=8, out_features=256, bias=True)\n",
            "  (vm_emb): Linear(in_features=4, out_features=256, bias=True)\n",
            "  (convs): ModuleList(\n",
            "    (0-2): 3 x HeteroConv(num_relations=4)\n",
            "  )\n",
            "  (out_mlp): Sequential(\n",
            "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=128, out_features=2, bias=True)\n",
            "  )\n",
            ")\n",
            "\n",
            "Saída Dummy GNN_Aval (shape): torch.Size([1, 2])\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "# ==============================================================================\n",
        "# CÉLULA 5: Modelo 1 - GNN de Avaliação (GNN_Aval)\n",
        "# ==============================================================================\n",
        "#\n",
        "# Esta GNN aprende a PREVER o Makespan e o Custo Total.\n",
        "# Ela atua como um \"simulador diferenciável\".\n",
        "#\n",
        "# Entrada: Um grafo PyG do problema.\n",
        "#          + Características da *alocação escolhida* adicionadas aos nós 'task'.\n",
        "# Saída: Um escalar para 'makespan' e um para 'cost_total'.\n",
        "#\n",
        "\n",
        "class GNN_Aval(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim, out_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        # Camada de entrada para 'task'.\n",
        "        # MELHORIA: A entrada agora é (6 features + 2 da alocação) = 8\n",
        "        self.task_emb = nn.Linear(8, hidden_dim) # 6 (features) + 2 (tempo, custo)\n",
        "        self.vm_emb = nn.Linear(4, hidden_dim)\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for _ in range(3): # 3 camadas de GNN\n",
        "            conv = HeteroConv({\n",
        "                ('task', 'depends_on', 'task'): GATConv(-1, hidden_dim),\n",
        "                ('task', 'rev_depends_on', 'task'): GATConv(-1, hidden_dim),\n",
        "                ('task', 'can_run_on', 'vm'): GATConv((-1, -1), hidden_dim, add_self_loops=False),\n",
        "                ('vm', 'rev_can_run_on', 'task'): GATConv((-1, -1), hidden_dim, add_self_loops=False),\n",
        "            }, aggr='sum')\n",
        "            self.convs.append(conv)\n",
        "\n",
        "        # MLP de Saída (prediz 2 valores)\n",
        "        self.out_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim // 2),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim // 2, out_dim) # out_dim = 2 (makespan, cost)\n",
        "        )\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_attr_dict):\n",
        "        # 1. Aplicar embeddings de entrada\n",
        "        x_dict['task'] = self.task_emb(x_dict['task']).relu()\n",
        "        x_dict['vm'] = self.vm_emb(x_dict['vm']).relu()\n",
        "\n",
        "        # 2. Camadas de Convolução\n",
        "        for conv in self.convs:\n",
        "            x_dict_update = conv(x_dict, edge_index_dict, edge_attr_dict)\n",
        "            # Atualiza características (com conexões residuais)\n",
        "            x_dict = {key: x_dict[key] + x_dict_update[key].relu() for key in x_dict.keys()}\n",
        "\n",
        "        # 3. Pooling Global\n",
        "        # Usamos o pool apenas dos nós 'task' para a predição global\n",
        "        task_pool = global_mean_pool(x_dict['task'], batch=None) # Assume batch_size=1\n",
        "\n",
        "        # 4. MLP de Saída\n",
        "        return self.out_mlp(task_pool)\n",
        "\n",
        "# --- Teste do Modelo (Instanciação) ---\n",
        "# Dimensões de embedding\n",
        "HIDDEN_DIM = 256\n",
        "# Dimensão de saída (makespan, cost_total)\n",
        "OUT_DIM = 2\n",
        "\n",
        "gnn_aval_model = GNN_Aval(hidden_dim=HIDDEN_DIM, out_dim=OUT_DIM)\n",
        "print(\"\\nEstrutura GNN_Aval:\")\n",
        "print(gnn_aval_model)\n",
        "\n",
        "# Teste de forward (com dados dummy)\n",
        "# Precisamos simular a entrada (x_dict com tempo/custo adicionados)\n",
        "dummy_data = create_pyg_data(test_dag, test_times, test_costs)\n",
        "num_tasks = dummy_data['task'].x.shape[0]\n",
        "\n",
        "# Simula adição de tempo/custo da alocação\n",
        "dummy_alloc_time = torch.randn(num_tasks, 1)\n",
        "dummy_alloc_cost = torch.randn(num_tasks, 1)\n",
        "# A entrada agora tem 6 features base + 2 de alocação\n",
        "dummy_data['task'].x = torch.cat([dummy_data['task'].x, dummy_alloc_time, dummy_alloc_cost], dim=1)\n",
        "\n",
        "# Passa pelo modelo\n",
        "pred = gnn_aval_model(dummy_data.x_dict, dummy_data.edge_index_dict, dummy_data.edge_attr_dict)\n",
        "print(f\"\\nSaída Dummy GNN_Aval (shape): {pred.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "ow9QoCRdMmw1",
        "outputId": "75ff86cb-162f-4617-9e62-46b10eafcb54"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iniciando Pré-treinamento da GNN_Aval...\n",
            "Epoch [20/5000], Loss (MSE): 0.4559, Acc. Makespan: 79.01%, Acc. Custo: 74.60%\n",
            "Epoch [40/5000], Loss (MSE): 0.3571, Acc. Makespan: 83.79%, Acc. Custo: 84.68%\n",
            "Epoch [60/5000], Loss (MSE): 0.2331, Acc. Makespan: 80.46%, Acc. Custo: 81.36%\n",
            "Epoch [80/5000], Loss (MSE): 0.3147, Acc. Makespan: 84.43%, Acc. Custo: 80.77%\n",
            "Epoch [100/5000], Loss (MSE): 0.1885, Acc. Makespan: 80.38%, Acc. Custo: 85.54%\n",
            "Epoch [120/5000], Loss (MSE): 0.2263, Acc. Makespan: 75.67%, Acc. Custo: 87.44%\n",
            "Epoch [140/5000], Loss (MSE): 0.1279, Acc. Makespan: 86.66%, Acc. Custo: 88.98%\n",
            "Epoch [160/5000], Loss (MSE): 0.1716, Acc. Makespan: 84.50%, Acc. Custo: 91.24%\n",
            "Epoch [180/5000], Loss (MSE): 0.2144, Acc. Makespan: 84.42%, Acc. Custo: 88.44%\n",
            "Epoch [200/5000], Loss (MSE): 0.1756, Acc. Makespan: 86.07%, Acc. Custo: 86.55%\n",
            "Epoch [220/5000], Loss (MSE): 0.1917, Acc. Makespan: 85.97%, Acc. Custo: 90.94%\n",
            "Epoch [240/5000], Loss (MSE): 0.1423, Acc. Makespan: 83.83%, Acc. Custo: 91.51%\n",
            "Epoch [260/5000], Loss (MSE): 0.1287, Acc. Makespan: 85.88%, Acc. Custo: 91.93%\n",
            "Epoch [280/5000], Loss (MSE): 0.1493, Acc. Makespan: 85.33%, Acc. Custo: 91.48%\n",
            "Epoch [300/5000], Loss (MSE): 0.1179, Acc. Makespan: 85.57%, Acc. Custo: 86.48%\n",
            "Epoch [320/5000], Loss (MSE): 0.1542, Acc. Makespan: 85.86%, Acc. Custo: 90.79%\n",
            "Epoch [340/5000], Loss (MSE): 0.1859, Acc. Makespan: 83.88%, Acc. Custo: 91.34%\n",
            "Epoch [360/5000], Loss (MSE): 0.1242, Acc. Makespan: 84.13%, Acc. Custo: 92.77%\n",
            "Epoch [380/5000], Loss (MSE): 0.1555, Acc. Makespan: 76.75%, Acc. Custo: 91.26%\n",
            "Epoch [400/5000], Loss (MSE): 0.1513, Acc. Makespan: 85.60%, Acc. Custo: 91.65%\n",
            "Epoch [420/5000], Loss (MSE): 0.1344, Acc. Makespan: 86.59%, Acc. Custo: 91.91%\n",
            "Epoch [440/5000], Loss (MSE): 0.1292, Acc. Makespan: 86.78%, Acc. Custo: 92.31%\n",
            "Epoch [460/5000], Loss (MSE): 0.1079, Acc. Makespan: 86.63%, Acc. Custo: 89.59%\n",
            "Epoch [480/5000], Loss (MSE): 0.1666, Acc. Makespan: 86.24%, Acc. Custo: 89.47%\n",
            "Epoch [500/5000], Loss (MSE): 0.1539, Acc. Makespan: 86.80%, Acc. Custo: 91.62%\n",
            "Epoch [520/5000], Loss (MSE): 0.1255, Acc. Makespan: 86.19%, Acc. Custo: 92.77%\n",
            "Epoch [540/5000], Loss (MSE): 0.1296, Acc. Makespan: 85.01%, Acc. Custo: 90.48%\n",
            "Epoch [560/5000], Loss (MSE): 0.1785, Acc. Makespan: 83.41%, Acc. Custo: 92.25%\n",
            "Epoch [580/5000], Loss (MSE): 0.1497, Acc. Makespan: 86.83%, Acc. Custo: 88.15%\n",
            "Epoch [600/5000], Loss (MSE): 0.1537, Acc. Makespan: 87.14%, Acc. Custo: 91.54%\n",
            "Epoch [620/5000], Loss (MSE): 0.1116, Acc. Makespan: 86.82%, Acc. Custo: 92.82%\n",
            "Epoch [640/5000], Loss (MSE): 0.1336, Acc. Makespan: 86.31%, Acc. Custo: 93.64%\n",
            "Epoch [660/5000], Loss (MSE): 0.1202, Acc. Makespan: 85.11%, Acc. Custo: 91.82%\n",
            "Epoch [680/5000], Loss (MSE): 0.1045, Acc. Makespan: 85.13%, Acc. Custo: 91.74%\n",
            "Epoch [700/5000], Loss (MSE): 0.1430, Acc. Makespan: 86.11%, Acc. Custo: 90.87%\n",
            "Epoch [720/5000], Loss (MSE): 0.1389, Acc. Makespan: 83.92%, Acc. Custo: 92.83%\n",
            "Epoch [740/5000], Loss (MSE): 0.1147, Acc. Makespan: 84.55%, Acc. Custo: 92.89%\n",
            "Epoch [760/5000], Loss (MSE): 0.1583, Acc. Makespan: 87.57%, Acc. Custo: 93.74%\n",
            "Epoch [780/5000], Loss (MSE): 0.1230, Acc. Makespan: 83.35%, Acc. Custo: 91.27%\n",
            "Epoch [800/5000], Loss (MSE): 0.1420, Acc. Makespan: 80.96%, Acc. Custo: 91.64%\n",
            "Epoch [820/5000], Loss (MSE): 0.1480, Acc. Makespan: 85.24%, Acc. Custo: 90.00%\n",
            "Epoch [840/5000], Loss (MSE): 0.1099, Acc. Makespan: 85.09%, Acc. Custo: 90.44%\n",
            "Epoch [860/5000], Loss (MSE): 0.1338, Acc. Makespan: 87.10%, Acc. Custo: 90.25%\n",
            "Epoch [880/5000], Loss (MSE): 0.0797, Acc. Makespan: 85.27%, Acc. Custo: 90.97%\n",
            "Epoch [900/5000], Loss (MSE): 0.1230, Acc. Makespan: 88.15%, Acc. Custo: 90.10%\n",
            "Epoch [920/5000], Loss (MSE): 0.1204, Acc. Makespan: 88.70%, Acc. Custo: 93.82%\n",
            "Epoch [940/5000], Loss (MSE): 0.1236, Acc. Makespan: 86.98%, Acc. Custo: 85.41%\n",
            "Epoch [960/5000], Loss (MSE): 0.1180, Acc. Makespan: 81.23%, Acc. Custo: 93.08%\n",
            "Epoch [980/5000], Loss (MSE): 0.1527, Acc. Makespan: 87.29%, Acc. Custo: 93.31%\n",
            "Epoch [1000/5000], Loss (MSE): 0.1639, Acc. Makespan: 87.54%, Acc. Custo: 93.10%\n",
            "Epoch [1020/5000], Loss (MSE): 0.1250, Acc. Makespan: 86.27%, Acc. Custo: 93.52%\n",
            "Epoch [1040/5000], Loss (MSE): 0.1238, Acc. Makespan: 85.09%, Acc. Custo: 94.14%\n",
            "Epoch [1060/5000], Loss (MSE): 0.1114, Acc. Makespan: 86.81%, Acc. Custo: 93.17%\n",
            "Epoch [1080/5000], Loss (MSE): 0.0988, Acc. Makespan: 86.85%, Acc. Custo: 94.00%\n",
            "Epoch [1100/5000], Loss (MSE): 0.1229, Acc. Makespan: 87.92%, Acc. Custo: 92.86%\n",
            "Epoch [1120/5000], Loss (MSE): 0.1129, Acc. Makespan: 87.93%, Acc. Custo: 93.26%\n",
            "Epoch [1140/5000], Loss (MSE): 0.1375, Acc. Makespan: 88.24%, Acc. Custo: 92.98%\n",
            "Epoch [1160/5000], Loss (MSE): 0.1055, Acc. Makespan: 86.32%, Acc. Custo: 92.85%\n",
            "Epoch [1180/5000], Loss (MSE): 0.1130, Acc. Makespan: 87.44%, Acc. Custo: 89.27%\n",
            "Epoch [1200/5000], Loss (MSE): 0.0982, Acc. Makespan: 86.85%, Acc. Custo: 92.74%\n",
            "Epoch [1220/5000], Loss (MSE): 0.1370, Acc. Makespan: 86.09%, Acc. Custo: 90.69%\n",
            "Epoch [1240/5000], Loss (MSE): 0.1203, Acc. Makespan: 87.27%, Acc. Custo: 92.33%\n",
            "Epoch [1260/5000], Loss (MSE): 0.1257, Acc. Makespan: 86.40%, Acc. Custo: 93.34%\n",
            "Epoch [1280/5000], Loss (MSE): 0.1887, Acc. Makespan: 79.62%, Acc. Custo: 87.82%\n",
            "Epoch [1300/5000], Loss (MSE): 0.1512, Acc. Makespan: 81.96%, Acc. Custo: 88.48%\n",
            "Epoch [1320/5000], Loss (MSE): 0.1493, Acc. Makespan: 84.69%, Acc. Custo: 91.69%\n",
            "Epoch [1340/5000], Loss (MSE): 0.1278, Acc. Makespan: 87.27%, Acc. Custo: 92.67%\n",
            "Epoch [1360/5000], Loss (MSE): 0.1486, Acc. Makespan: 81.94%, Acc. Custo: 90.33%\n",
            "Epoch [1380/5000], Loss (MSE): 0.1281, Acc. Makespan: 81.87%, Acc. Custo: 91.72%\n",
            "Epoch [1400/5000], Loss (MSE): 0.1003, Acc. Makespan: 85.61%, Acc. Custo: 94.62%\n",
            "Epoch [1420/5000], Loss (MSE): 0.1083, Acc. Makespan: 87.13%, Acc. Custo: 93.68%\n",
            "Epoch [1440/5000], Loss (MSE): 0.1651, Acc. Makespan: 87.16%, Acc. Custo: 91.90%\n",
            "Epoch [1460/5000], Loss (MSE): 0.1011, Acc. Makespan: 86.64%, Acc. Custo: 90.57%\n",
            "Epoch [1480/5000], Loss (MSE): 0.1914, Acc. Makespan: 86.12%, Acc. Custo: 87.39%\n",
            "Epoch [1500/5000], Loss (MSE): 0.1007, Acc. Makespan: 87.32%, Acc. Custo: 91.51%\n",
            "Epoch [1520/5000], Loss (MSE): 0.1585, Acc. Makespan: 82.85%, Acc. Custo: 93.13%\n",
            "Epoch [1540/5000], Loss (MSE): 0.1124, Acc. Makespan: 87.45%, Acc. Custo: 91.82%\n",
            "Epoch [1560/5000], Loss (MSE): 0.1366, Acc. Makespan: 87.52%, Acc. Custo: 92.49%\n",
            "Epoch [1580/5000], Loss (MSE): 0.1353, Acc. Makespan: 89.24%, Acc. Custo: 92.58%\n",
            "Epoch [1600/5000], Loss (MSE): 0.1132, Acc. Makespan: 86.33%, Acc. Custo: 90.05%\n",
            "Epoch [1620/5000], Loss (MSE): 0.1246, Acc. Makespan: 84.96%, Acc. Custo: 89.88%\n",
            "Epoch [1640/5000], Loss (MSE): 0.1504, Acc. Makespan: 86.94%, Acc. Custo: 92.92%\n",
            "Epoch [1660/5000], Loss (MSE): 0.1256, Acc. Makespan: 86.43%, Acc. Custo: 90.12%\n",
            "Epoch [1680/5000], Loss (MSE): 0.1367, Acc. Makespan: 84.10%, Acc. Custo: 93.36%\n",
            "Epoch [1700/5000], Loss (MSE): 0.1429, Acc. Makespan: 88.33%, Acc. Custo: 90.95%\n",
            "Epoch [1720/5000], Loss (MSE): 0.1443, Acc. Makespan: 85.56%, Acc. Custo: 86.24%\n",
            "Epoch [1740/5000], Loss (MSE): 0.1278, Acc. Makespan: 88.07%, Acc. Custo: 92.81%\n",
            "Epoch [1760/5000], Loss (MSE): 0.1378, Acc. Makespan: 85.74%, Acc. Custo: 93.62%\n",
            "Epoch [1780/5000], Loss (MSE): 0.1240, Acc. Makespan: 87.45%, Acc. Custo: 92.49%\n",
            "Epoch [1800/5000], Loss (MSE): 0.1208, Acc. Makespan: 85.74%, Acc. Custo: 89.80%\n",
            "Epoch [1820/5000], Loss (MSE): 0.1077, Acc. Makespan: 87.31%, Acc. Custo: 91.12%\n",
            "Epoch [1840/5000], Loss (MSE): 0.1200, Acc. Makespan: 86.17%, Acc. Custo: 93.00%\n",
            "Epoch [1860/5000], Loss (MSE): 0.1288, Acc. Makespan: 86.48%, Acc. Custo: 92.78%\n",
            "Epoch [1880/5000], Loss (MSE): 0.1413, Acc. Makespan: 87.86%, Acc. Custo: 93.72%\n",
            "Epoch [1900/5000], Loss (MSE): 0.1490, Acc. Makespan: 82.26%, Acc. Custo: 91.43%\n",
            "Epoch [1920/5000], Loss (MSE): 0.0955, Acc. Makespan: 85.85%, Acc. Custo: 90.68%\n",
            "Epoch [1940/5000], Loss (MSE): 0.1416, Acc. Makespan: 85.19%, Acc. Custo: 93.45%\n",
            "Epoch [1960/5000], Loss (MSE): 0.1067, Acc. Makespan: 87.41%, Acc. Custo: 92.70%\n",
            "Epoch [1980/5000], Loss (MSE): 0.1023, Acc. Makespan: 84.35%, Acc. Custo: 91.56%\n",
            "Epoch [2000/5000], Loss (MSE): 0.1209, Acc. Makespan: 87.10%, Acc. Custo: 93.06%\n",
            "Epoch [2020/5000], Loss (MSE): 0.1178, Acc. Makespan: 87.98%, Acc. Custo: 93.47%\n",
            "Epoch [2040/5000], Loss (MSE): 0.1089, Acc. Makespan: 84.66%, Acc. Custo: 93.19%\n",
            "Epoch [2060/5000], Loss (MSE): 0.1469, Acc. Makespan: 86.83%, Acc. Custo: 91.35%\n",
            "Epoch [2080/5000], Loss (MSE): 0.1056, Acc. Makespan: 86.24%, Acc. Custo: 93.81%\n",
            "Epoch [2100/5000], Loss (MSE): 0.0929, Acc. Makespan: 88.51%, Acc. Custo: 95.60%\n",
            "Epoch [2120/5000], Loss (MSE): 0.1271, Acc. Makespan: 85.98%, Acc. Custo: 93.00%\n",
            "Epoch [2140/5000], Loss (MSE): 0.1202, Acc. Makespan: 89.52%, Acc. Custo: 92.92%\n",
            "Epoch [2160/5000], Loss (MSE): 0.1117, Acc. Makespan: 86.86%, Acc. Custo: 92.59%\n",
            "Epoch [2180/5000], Loss (MSE): 0.1619, Acc. Makespan: 84.96%, Acc. Custo: 90.73%\n",
            "Epoch [2200/5000], Loss (MSE): 0.1453, Acc. Makespan: 81.95%, Acc. Custo: 91.85%\n",
            "Epoch [2220/5000], Loss (MSE): 0.1298, Acc. Makespan: 84.46%, Acc. Custo: 89.08%\n",
            "Epoch [2240/5000], Loss (MSE): 0.0901, Acc. Makespan: 86.77%, Acc. Custo: 94.50%\n",
            "Epoch [2260/5000], Loss (MSE): 0.1088, Acc. Makespan: 87.18%, Acc. Custo: 91.32%\n",
            "Epoch [2280/5000], Loss (MSE): 0.1147, Acc. Makespan: 83.53%, Acc. Custo: 89.28%\n",
            "Epoch [2300/5000], Loss (MSE): 0.1018, Acc. Makespan: 87.94%, Acc. Custo: 93.99%\n",
            "Epoch [2320/5000], Loss (MSE): 0.1170, Acc. Makespan: 88.34%, Acc. Custo: 92.93%\n",
            "Epoch [2340/5000], Loss (MSE): 0.1010, Acc. Makespan: 87.19%, Acc. Custo: 93.62%\n",
            "Epoch [2360/5000], Loss (MSE): 0.0923, Acc. Makespan: 85.24%, Acc. Custo: 94.08%\n"
          ]
        }
      ],
      "source": [
        "# %%\n",
        "# ==============================================================================\n",
        "# CÉLULA 6: Fase 1 - Pré-treinamento da GNN_Aval\n",
        "# ==============================================================================\n",
        "#\n",
        "# Objetivo: Ensinar a GNN_Aval a ser um bom simulador.\n",
        "#\n",
        "# 1. Gerar (Problema, Alocação) -> **MELHORIA: Usar heurísticas, não só aleatório**\n",
        "# 2. Calcular (Makespan Real, Custo Real) com o simulador (Célula 3)\n",
        "# 3. **MELHORIA: Normalizar (Makespan, Custo) para a loss ser estável**\n",
        "# 4. Treinar GNN_Aval(Problema + Alocação) para prever (Makespan Norm, Custo Norm)\n",
        "# 5. Loss: MSE\n",
        "#\n",
        "\n",
        "class TargetNormalizer:\n",
        "    \"\"\"Classe simples para normalizar os alvos (makespan, custo)\"\"\"\n",
        "    def __init__(self, momentum=0.99):\n",
        "        self.momentum = momentum\n",
        "        self.mean = torch.tensor([0.0, 0.0], dtype=torch.float32)\n",
        "        self.var = torch.tensor([1.0, 1.0], dtype=torch.float32)\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, y_true_batch):\n",
        "        # y_true_batch é (N, 2)\n",
        "        batch_mean = torch.mean(y_true_batch, dim=0)\n",
        "        batch_var = torch.var(y_true_batch, dim=0)\n",
        "\n",
        "        if self.count == 0:\n",
        "            self.mean = batch_mean\n",
        "            self.var = batch_var\n",
        "        else:\n",
        "            self.mean = self.momentum * self.mean + (1 - self.momentum) * batch_mean\n",
        "            self.var = self.momentum * self.var + (1 - self.momentum) * batch_var\n",
        "\n",
        "        self.count += y_true_batch.shape[0]\n",
        "\n",
        "    def normalize(self, y):\n",
        "        return (y - self.mean) / (torch.sqrt(self.var) + 1e-6)\n",
        "\n",
        "    def denormalize(self, y_norm):\n",
        "        return y_norm * (torch.sqrt(self.var) + 1e-6) + self.mean\n",
        "\n",
        "    # ADICIONA state_dict\n",
        "    def state_dict(self):\n",
        "        return {\n",
        "            'mean': self.mean,\n",
        "            'var': self.var,\n",
        "            'count': self.count\n",
        "        }\n",
        "\n",
        "    # ADICIONA load_state_dict\n",
        "    def load_state_dict(self, state_dict):\n",
        "        self.mean = state_dict['mean']\n",
        "        self.var = state_dict['var']\n",
        "        self.count = state_dict['count']\n",
        "\n",
        "def create_training_sample_for_aval(num_tasks_base, num_vms):\n",
        "    \"\"\"Gera um único ponto de dados para o pré-treino da GNN_Aval.\"\"\"\n",
        "\n",
        "    # 1. Gerar Problema\n",
        "    num_tasks = num_tasks_base + random.randint(-2, 5) # Variar tamanho\n",
        "    dag = generate_workflow_dag(num_tasks)\n",
        "    num_nodes = dag.number_of_nodes()\n",
        "\n",
        "    time_m, cost_m = generate_cost_time_matrix(num_nodes, num_vms)\n",
        "\n",
        "    # Força custo/tempo 0 para source/sink\n",
        "    source_node = list(nx.topological_sort(dag))[0]\n",
        "    sink_node = list(nx.topological_sort(dag))[-1]\n",
        "    time_m[source_node, :] = 0\n",
        "    time_m[sink_node, :] = 0\n",
        "    cost_m[source_node, :] = 0\n",
        "    cost_m[sink_node, :] = 0\n",
        "\n",
        "    # 2. Gerar Alocação (MELHORIA: 1/3 aleatório, 1/3 rápido, 1/3 barato)\n",
        "    rand_choice = random.random()\n",
        "    if rand_choice < 0.33:\n",
        "        alloc_dict = {node_id: random.randint(0, num_vms - 1) for node_id in dag.nodes()}\n",
        "    elif rand_choice < 0.66:\n",
        "        alloc_dict = heuristic_fastest(dag, time_m)\n",
        "    else:\n",
        "        alloc_dict = heuristic_cheapest(dag, cost_m)\n",
        "\n",
        "    # Define alocação de source/sink\n",
        "    alloc_dict[source_node] = 0\n",
        "    alloc_dict[sink_node] = 0\n",
        "\n",
        "    # 3. Calcular Métricas Reais (Ground Truth)\n",
        "    makespan, total_cost = calculate_metrics(dag, alloc_dict, time_m, cost_m)\n",
        "    y_true = torch.tensor([makespan, total_cost], dtype=torch.float32)\n",
        "\n",
        "    # 4. Criar dados de entrada para GNN_Aval\n",
        "    pyg_data = create_pyg_data(dag, time_m, cost_m)\n",
        "\n",
        "    alloc_times = torch.zeros(num_nodes, 1)\n",
        "    alloc_costs = torch.zeros(num_nodes, 1)\n",
        "\n",
        "    for node_id, vm_id in alloc_dict.items():\n",
        "        # A CORREÇÃO DO TypeError VEM AQUI:\n",
        "        alloc_times[node_id] = torch.tensor(time_m[node_id, vm_id])\n",
        "        alloc_costs[node_id] = torch.tensor(cost_m[node_id, vm_id])\n",
        "\n",
        "    # Normalização (simples)\n",
        "    alloc_times = (alloc_times - alloc_times.mean()) / (alloc_times.std() + 1e-6)\n",
        "    alloc_costs = (alloc_costs - alloc_costs.mean()) / (alloc_costs.std() + 1e-6)\n",
        "\n",
        "    # Concatena as 6 features base + 2 features de alocação\n",
        "    pyg_data['task'].x = torch.cat([pyg_data['task'].x, alloc_times, alloc_costs], dim=1)\n",
        "\n",
        "    return pyg_data, y_true\n",
        "\n",
        "# --- MELHORIA: Função de Validação ---\n",
        "def validate_gnn_aval(model, normalizer, num_samples=100):\n",
        "    model.eval() # Coloca o modelo em modo de avaliação\n",
        "\n",
        "    all_mape_m = [] # Erro percentual do Makespan\n",
        "    all_mape_c = [] # Erro percentual do Custo\n",
        "\n",
        "    with torch.no_grad(): # Não calcula gradientes\n",
        "        for _ in range(num_samples):\n",
        "            # 1. Gera um novo problema de validação\n",
        "            data, y_true_real = create_training_sample_for_aval(num_tasks_base=15, num_vms=4)\n",
        "\n",
        "            # 2. Faz a predição\n",
        "            y_pred_norm = model(data.x_dict, data.edge_index_dict, data.edge_attr_dict)\n",
        "\n",
        "            # 3. Desnormaliza a predição para comparar com o real\n",
        "            y_pred_real = normalizer.denormalize(y_pred_norm.squeeze())\n",
        "\n",
        "            # 4. Calcula o Erro Percentual Absoluto (MAPE)\n",
        "            # (evita divisão por zero se y_true_real for 0)\n",
        "            mape_m = torch.abs((y_pred_real[0] - y_true_real[0]) / (y_true_real[0] + 1e-6))\n",
        "            mape_c = torch.abs((y_pred_real[1] - y_true_real[1]) / (y_true_real[1] + 1e-6))\n",
        "\n",
        "            all_mape_m.append(mape_m)\n",
        "            all_mape_c.append(mape_c)\n",
        "\n",
        "    model.train() # Volta ao modo de treino\n",
        "\n",
        "    # Calcula a acurácia como (1.0 - ErroMédio)\n",
        "    avg_mape_m = torch.stack(all_mape_m).mean().item()\n",
        "    avg_mape_c = torch.stack(all_mape_c).mean().item()\n",
        "\n",
        "    acc_m = 100.0 * (1.0 - avg_mape_m)\n",
        "    acc_c = 100.0 * (1.0 - avg_mape_c)\n",
        "\n",
        "    return acc_m, acc_c\n",
        "\n",
        "# --- Loop de Treinamento GNN_Aval ---\n",
        "print(\"\\nIniciando Pré-treinamento da GNN_Aval...\")\n",
        "\n",
        "gnn_aval = GNN_Aval(hidden_dim=HIDDEN_DIM, out_dim=OUT_DIM)\n",
        "optimizer_aval = optim.Adam(gnn_aval.parameters(), lr=1e-3)\n",
        "loss_fn_aval = nn.MSELoss()\n",
        "\n",
        "# MELHORIA: Normalizador de Alvo\n",
        "target_normalizer = TargetNormalizer()\n",
        "\n",
        "NUM_EPOCHS_AVAL = 5000 # Aumentado para treinar a \"professora\" melhor\n",
        "STEPS_PER_EPOCH_AVAL = 100\n",
        "BATCH_SIZE_AVAL = 16 # Treinar em lotes\n",
        "\n",
        "for epoch in range(NUM_EPOCHS_AVAL):\n",
        "    epoch_loss = 0.0\n",
        "\n",
        "    # Acumular um lote\n",
        "    batch_data = []\n",
        "    batch_y_true = []\n",
        "    for _ in range(STEPS_PER_EPOCH_AVAL * BATCH_SIZE_AVAL):\n",
        "        data, y_true = create_training_sample_for_aval(num_tasks_base=15, num_vms=4)\n",
        "        batch_data.append(data)\n",
        "        batch_y_true.append(y_true)\n",
        "\n",
        "    batch_y_true = torch.stack(batch_y_true)\n",
        "    target_normalizer.update(batch_y_true) # Atualiza média/var\n",
        "\n",
        "    # Normaliza os alvos do lote\n",
        "    batch_y_true_norm = target_normalizer.normalize(batch_y_true)\n",
        "\n",
        "    # Treinar em mini-lotes\n",
        "    for i in range(STEPS_PER_EPOCH_AVAL):\n",
        "        optimizer_aval.zero_grad()\n",
        "\n",
        "        # Simplesmente pegamos um item (para manter a estrutura do código anterior)\n",
        "        # Idealmente, usaríamos um DataLoader do PyG, mas isso complica\n",
        "        idx = i * BATCH_SIZE_AVAL # Apenas para o loss, vamos treinar 1 por 1\n",
        "\n",
        "        data = batch_data[idx]\n",
        "        y_true_norm = batch_y_true_norm[idx]\n",
        "\n",
        "        # Forward pass\n",
        "        y_pred_norm = gnn_aval(data.x_dict, data.edge_index_dict, data.edge_attr_dict)\n",
        "\n",
        "        loss = loss_fn_aval(y_pred_norm.squeeze(), y_true_norm)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer_aval.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        # MELHORIA: Roda a validação e imprime a acurácia\n",
        "        acc_m, acc_c = validate_gnn_aval(gnn_aval, target_normalizer)\n",
        "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS_AVAL}], Loss (MSE): {epoch_loss/STEPS_PER_EPOCH_AVAL:.4f}, \"\n",
        "              f\"Acc. Makespan: {acc_m:.2f}%, Acc. Custo: {acc_c:.2f}%\")\n",
        "\n",
        "print(\"Pré-treinamento da GNN_Aval concluído.\")\n",
        "\n",
        "# Salvar o modelo treinado E o normalizador\n",
        "torch.save(gnn_aval.state_dict(), \"gnn_aval_pretrained.pth\")\n",
        "# MUDANÇA: Salvar o state_dict, não o objeto\n",
        "torch.save(target_normalizer.state_dict(), \"gnn_aval_normalizer.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BIgg-M0wMv5A"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# ==============================================================================\n",
        "# CÉLULA 7: Modelo 2 - GNN de Alocação (GNN_Aloc)\n",
        "# ==============================================================================\n",
        "#\n",
        "# Esta GNN aprende a PROPOR uma alocação.\n",
        "#\n",
        "# Entrada: Um grafo PyG do problema (sem infos de alocação).\n",
        "# Saída: Para cada nó 'task', um vetor de probabilidades (softmax)\n",
        "#        sobre qual 'vm' escolher.\n",
        "#\n",
        "\n",
        "class GNN_Aloc(torch.nn.Module):\n",
        "    def __init__(self, hidden_dim, num_vms):\n",
        "        super().__init__()\n",
        "\n",
        "        # A CORREÇÃO ESTÁ AQUI:\n",
        "        # A GNN_Aloc recebe apenas as 6 features base, e não as 8 (6+2) que a GNN_Aval recebe.\n",
        "        self.task_emb = nn.Linear(6, hidden_dim) # 6 = dim das features base (mean, std, min para tempo/custo)\n",
        "        self.vm_emb = nn.Linear(4, hidden_dim)   # 4 = dim inicial\n",
        "\n",
        "        self.convs = torch.nn.ModuleList()\n",
        "        for _ in range(3): # 3 camadas de GNN\n",
        "            conv = HeteroConv({\n",
        "                ('task', 'depends_on', 'task'): GATConv(-1, hidden_dim),\n",
        "                ('task', 'rev_depends_on', 'task'): GATConv(-1, hidden_dim),\n",
        "                # Aresta de alocação (com atributos de tempo/custo)\n",
        "                # APLICA A MESMA CORREÇÃO AQUI\n",
        "                ('task', 'can_run_on', 'vm'): GATConv((-1, -1), hidden_dim, edge_dim=2, add_self_loops=False),\n",
        "                ('vm', 'rev_can_run_on', 'task'): GATConv((-1, -1), hidden_dim, edge_dim=2, add_self_loops=False),\n",
        "            }, aggr='sum')\n",
        "            self.convs.append(conv)\n",
        "\n",
        "        # MLP de Saída (para cada nó 'task', prediz um score por VM)\n",
        "        self.out_mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, num_vms) # Saída: [N_tasks, N_vms] scores\n",
        "        )\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict, edge_attr_dict, gumbel_tau=1.0):\n",
        "        # 1. Aplicar embeddings de entrada\n",
        "        x_dict['task'] = self.task_emb(x_dict['task']).relu()\n",
        "        x_dict['vm'] = self.vm_emb(x_dict['vm']).relu()\n",
        "\n",
        "        # 2. Camadas de Convolução\n",
        "        # REMOVIDO: O código manual e incorreto de 'conv_args' e 'conv_kwargs'\n",
        "\n",
        "        for conv in self.convs:\n",
        "            # A CORREÇÃO ESTÁ AQUI:\n",
        "            # Simplesmente passamos todos os dicionários. A HeteroConv\n",
        "            # é inteligente o suficiente para rotear os 'edge_attr'\n",
        "            # apenas para as camadas GATConv que os esperam (aquelas com edge_dim=2).\n",
        "            x_dict_update = conv(x_dict, edge_index_dict, edge_attr_dict=edge_attr_dict)\n",
        "            x_dict = {key: x_dict[key] + x_dict_update[key].relu() for key in x_dict.keys()}\n",
        "\n",
        "        # 3. Obter embeddings finais das tarefas\n",
        "        task_embeddings = x_dict['task']\n",
        "\n",
        "        # 4. MLP de Saída -> Scores de Alocação\n",
        "        alloc_logits = self.out_mlp(task_embeddings)\n",
        "\n",
        "        # 5. Aplicar Gumbel-Softmax\n",
        "        # MELHORIA: Usar hard=True.\n",
        "        # Isso usa o \"Straight-Through Estimator\" (STE).\n",
        "        # Forward: passa o one-hot (diferente de 'soft_alloc' anterior)\n",
        "        # Backward: passa o gradiente da versão 'soft'\n",
        "        hard_alloc = F.gumbel_softmax(alloc_logits, tau=gumbel_tau, hard=True, dim=-1)\n",
        "\n",
        "        return alloc_logits, hard_alloc\n",
        "\n",
        "# --- Teste do Modelo (Instanciação) ---\n",
        "gnn_aloc_model = GNN_Aloc(hidden_dim=HIDDEN_DIM, num_vms=NUM_VMS_TEST)\n",
        "print(\"\\nEstrutura GNN_Aloc:\")\n",
        "print(gnn_aloc_model)\n",
        "\n",
        "# Teste de forward\n",
        "logits, hard_alloc = gnn_aloc_model(pyg_data.x_dict, pyg_data.edge_index_dict, pyg_data.edge_attr_dict)\n",
        "print(f\"\\nSaída Logits GNN_Aloc (shape): {logits.shape}\") # (N_tasks, N_vms)\n",
        "print(f\"Saída Hard Alloc GNN_Aloc (shape): {hard_alloc.shape}\") # (N_tasks, N_vms)\n",
        "print(f\"Exemplo Hard Alloc (task 0): {hard_alloc[0]}\") # Deve ser [0., 1., 0.] ou similar\n",
        "print(f\"Soma da Hard Alloc (task 0): {hard_alloc[0].sum().item()}\") # Deve ser 1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BV_muuXjHcXC"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# ==============================================================================\n",
        "# CÉLULA 8: Fase 2 - Treinamento da GNN_Aloc (Não-Supervisionado)\n",
        "# ==============================================================================\n",
        "#\n",
        "# O \"Loop Mágico\" (Artigo 2)\n",
        "#\n",
        "# 1. Carregar GNN_Aval pré-treinada e CONGELAR (modo .eval())\n",
        "# 2. Carregar o Normalizador\n",
        "# 3. Gerar um novo Problema (DAG, Matrizes)\n",
        "# 4. Passar Problema pela GNN_Aloc -> obter 'hard_allocation' (one-hot)\n",
        "# 5. Calcular features de alocação (tempo/custo) a partir da 'hard_allocation'\n",
        "# 6. Criar o grafo de entrada para a GNN_Aval (com as features \"duras\")\n",
        "# 7. Passar pela GNN_Aval (congelada) -> prever (makespan_norm, cost_norm)\n",
        "# 8. A SAÍDA da GNN_Aval (normalizada) É A NOSSA LOSS!\n",
        "# 9. Backpropagate a 'loss' e ATUALIZAR GNN_Aloc.\n",
        "#\n",
        "\n",
        "print(\"\\nIniciando Treinamento da GNN_Aloc...\")\n",
        "\n",
        "# 1. Carregar GNN_Aval\n",
        "gnn_aval_frozen = GNN_Aval(hidden_dim=HIDDEN_DIM, out_dim=OUT_DIM)\n",
        "gnn_aval_frozen.load_state_dict(torch.load(\"gnn_aval_pretrained.pth\"))\n",
        "gnn_aval_frozen.eval() # Modo de avaliação (congela)\n",
        "print(\"GNN_Aval carregada e congelada.\")\n",
        "\n",
        "# 2. Carregar Normalizador\n",
        "# MUDANÇA: Criar uma nova instância e carregar o state_dict nela\n",
        "target_normalizer = TargetNormalizer()\n",
        "target_normalizer.load_state_dict(torch.load(\"gnn_aval_normalizer.pth\"))\n",
        "print(\"Normalizador de alvos carregado.\")\n",
        "\n",
        "# 3. Inicializar GNN_Aloc\n",
        "NUM_VMS = 4\n",
        "gnn_aloc = GNN_Aloc(hidden_dim=HIDDEN_DIM, num_vms=NUM_VMS)\n",
        "optimizer_aloc = optim.Adam(gnn_aloc.parameters(), lr=1e-5) # LR menor é mais seguro\n",
        "\n",
        "# Pesos da nossa função de utilidade (o que queremos minimizar)\n",
        "# Vamos focar 100% no Makespan por enquanto\n",
        "W_TIME = 1.0\n",
        "W_COST = 0.0 # Você pode mudar para 0.5, 0.5 por ex.\n",
        "\n",
        "# Parâmetros do Gumbel-Softmax\n",
        "gumbel_tau = 1.0 # Temperatura (pode ser \"annealed\" - diminuída ao longo do tempo)\n",
        "\n",
        "# --- Loop de Treinamento GNN_Aloc ---\n",
        "NUM_EPOCHS_ALOC = 5000 # Vamos rodar mais\n",
        "STEPS_PER_EPOCH_ALOC = 100\n",
        "\n",
        "for epoch in range(NUM_EPOCHS_ALOC):\n",
        "    epoch_loss = 0.0\n",
        "    for _ in range(STEPS_PER_EPOCH_ALOC):\n",
        "\n",
        "        # 3. Gerar Problema\n",
        "        num_tasks = 15 + random.randint(-2, 5)\n",
        "        dag = generate_workflow_dag(num_tasks)\n",
        "        num_nodes = dag.number_of_nodes()\n",
        "        time_m, cost_m = generate_cost_time_matrix(num_nodes, NUM_VMS)\n",
        "\n",
        "        # Zerar source/sink\n",
        "        source_node = list(nx.topological_sort(dag))[0]\n",
        "        sink_node = list(nx.topological_sort(dag))[-1]\n",
        "        time_m[source_node, :] = 0\n",
        "        time_m[sink_node, :] = 0\n",
        "        cost_m[source_node, :] = 0\n",
        "        cost_m[sink_node, :] = 0\n",
        "\n",
        "        time_m_t = torch.from_numpy(time_m).float()\n",
        "        cost_m_t = torch.from_numpy(cost_m).float()\n",
        "\n",
        "        # Criar grafo base (sem features de alocação)\n",
        "        data_aloc = create_pyg_data(dag, time_m, cost_m)\n",
        "\n",
        "        optimizer_aloc.zero_grad()\n",
        "\n",
        "        # 4. Forward GNN_Aloc -> 'hard_alloc' (one-hot)\n",
        "        _, hard_alloc = gnn_aloc(data_aloc.x_dict,\n",
        "                                data_aloc.edge_index_dict,\n",
        "                                data_aloc.edge_attr_dict,\n",
        "                                gumbel_tau)\n",
        "\n",
        "        # 5. Calcular features de alocação\n",
        "        # (N_tasks, N_vms) * (N_tasks, N_vms) -> sum(dim=1)\n",
        "        alloc_time = (hard_alloc * time_m_t).sum(dim=1, keepdim=True)\n",
        "        alloc_cost = (hard_alloc * cost_m_t).sum(dim=1, keepdim=True)\n",
        "\n",
        "        # Normalizar (para a entrada da GNN_Aval)\n",
        "        alloc_time_norm = (alloc_time - alloc_time.mean()) / (alloc_time.std() + 1e-6)\n",
        "        alloc_cost_norm = (alloc_cost - alloc_cost.mean()) / (alloc_cost.std() + 1e-6)\n",
        "\n",
        "        # 6. Criar grafo de entrada para GNN_Aval\n",
        "        data_aval_in = data_aloc.clone()\n",
        "        data_aval_in['task'].x = torch.cat([data_aloc['task'].x, alloc_time_norm, alloc_cost_norm], dim=1)\n",
        "\n",
        "        # 7. Forward GNN_Aval (congelada)\n",
        "        # Não precisamos de 'no_grad' aqui, pois o 'hard_alloc'\n",
        "        # já quebrou o grafo computacional. O gradiente flui pelo\n",
        "        # truque do Gumbel (STE).\n",
        "        pred_metrics_norm = gnn_aval_frozen(data_aval_in.x_dict,\n",
        "                                            data_aval_in.edge_index_dict,\n",
        "                                            data_aval_in.edge_attr_dict)\n",
        "\n",
        "        pred_makespan_norm = pred_metrics_norm[0, 0]\n",
        "        pred_cost_norm = pred_metrics_norm[0, 1]\n",
        "\n",
        "        # 8. Calcular a Loss (a própria saída normalizada da GNN_Aval)\n",
        "        loss = W_TIME * pred_makespan_norm + W_COST * pred_cost_norm\n",
        "\n",
        "        # 9. Backpropagate e atualizar GNN_Aloc\n",
        "        loss.backward()\n",
        "        optimizer_aloc.step()\n",
        "\n",
        "        epoch_loss += loss.item()\n",
        "\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        # Denormaliza a loss apenas para exibição\n",
        "        pred_denorm = target_normalizer.denormalize(pred_metrics_norm.detach())\n",
        "        loss_real = W_TIME * pred_denorm[0,0] + W_COST * pred_denorm[0,1]\n",
        "        print(f\"Epoch [{epoch+1}/{NUM_EPOCHS_ALOC}], Loss (Norm): {epoch_loss/STEPS_PER_EPOCH_ALOC:.4f}, Loss (Estim. Real): {loss_real:.2f}\")\n",
        "\n",
        "print(\"Treinamento da GNN_Aloc concluído.\")\n",
        "\n",
        "# Salvar o modelo alocador treinado\n",
        "torch.save(gnn_aloc.state_dict(), \"gnn_aloc_final.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1pC5W4xhTF1b"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# ==============================================================================\n",
        "# CÉLULA 9: Avaliação e Análise\n",
        "# ==============================================================================\n",
        "#\n",
        "# Agora comparamos nossa GNN_Aloc treinada com uma heurística simples.\n",
        "#\n",
        "# 1. Carregar GNN_Aloc treinada.\n",
        "# 2. Gerar um novo conjunto de problemas (teste).\n",
        "# 3. Para cada problema:\n",
        "#    a. Calcular alocação da GNN_Aloc (agora usando argmax, não gumbel)\n",
        "#    b. Calcular alocação da Heurística (e.g., \"GRASP\" ou \"Mais Rápido\")\n",
        "# 4. Usar o SIMULADOR (Célula 3) para obter os CUSTOS REAIS de ambas.\n",
        "# 5. Comparar os resultados.\n",
        "#\n",
        "\n",
        "print(\"\\nIniciando Avaliação...\")\n",
        "\n",
        "# 1. Carregar modelo\n",
        "gnn_aloc_eval = GNN_Aloc(hidden_dim=HIDDEN_DIM, num_vms=NUM_VMS)\n",
        "gnn_aloc_eval.load_state_dict(torch.load(\"gnn_aloc_final.pth\"))\n",
        "gnn_aloc_eval.eval()\n",
        "\n",
        "# 2. Heurística Simples (Baseline 1: \"Mais Rápido\")\n",
        "def heuristic_fastest(dag, time_m):\n",
        "    alloc_dict = {}\n",
        "    for node_id in dag.nodes():\n",
        "        # Encontra a VM com o menor tempo de execução para esta tarefa\n",
        "        vm_id = np.argmin(time_m[node_id])\n",
        "        alloc_dict[node_id] = vm_id\n",
        "    return alloc_dict\n",
        "\n",
        "# 3. Heurística Simples (Baseline 2: \"Mais Barato\")\n",
        "def heuristic_cheapest(dag, cost_m):\n",
        "    alloc_dict = {}\n",
        "    for node_id in dag.nodes():\n",
        "        # Encontra a VM com o menor custo de execução para esta tarefa\n",
        "        vm_id = np.argmin(cost_m[node_id])\n",
        "        alloc_dict[node_id] = vm_id\n",
        "    return alloc_dict\n",
        "\n",
        "# --- Loop de Avaliação ---\n",
        "NUM_TEST_PROBLEMS = 50\n",
        "results = {\n",
        "    'gnn_makespan': [], 'gnn_cost': [],\n",
        "    'fastest_makespan': [], 'fastest_cost': [],\n",
        "    'cheapest_makespan': [], 'cheapest_cost': [],\n",
        "}\n",
        "\n",
        "for i in range(NUM_TEST_PROBLEMS):\n",
        "    # Gerar problema de teste\n",
        "    num_tasks = 20 # Tamanho fixo para teste\n",
        "    dag = generate_workflow_dag(num_tasks)\n",
        "    num_nodes = dag.number_of_nodes()\n",
        "    time_m, cost_m = generate_cost_time_matrix(num_nodes, NUM_VMS)\n",
        "\n",
        "    source_node = list(nx.topological_sort(dag))[0]\n",
        "    sink_node = list(nx.topological_sort(dag))[-1]\n",
        "    time_m[source_node, :] = 0\n",
        "    time_m[sink_node, :] = 0\n",
        "    cost_m[source_node, :] = 0\n",
        "    cost_m[sink_node, :] = 0\n",
        "\n",
        "    # --- a. Avaliação da GNN ---\n",
        "    data_test = create_pyg_data(dag, time_m, cost_m)\n",
        "    with torch.no_grad():\n",
        "        logits_gnn, _ = gnn_aloc_eval(data_test.x_dict,\n",
        "                                     data_test.edge_index_dict,\n",
        "                                     data_test.edge_attr_dict)\n",
        "\n",
        "    # Usar argmax para obter a alocação \"hard\" (decisão final)\n",
        "    hard_alloc_gnn = logits_gnn.argmax(dim=-1).cpu().numpy()\n",
        "    alloc_dict_gnn = {node_id: vm_id for node_id, vm_id in enumerate(hard_alloc_gnn)}\n",
        "\n",
        "    m_gnn, c_gnn = calculate_metrics(dag, alloc_dict_gnn, time_m, cost_m)\n",
        "    results['gnn_makespan'].append(m_gnn)\n",
        "    results['gnn_cost'].append(c_gnn)\n",
        "\n",
        "    # --- b. Avaliação da Heurística \"Fastest\" ---\n",
        "    alloc_dict_fastest = heuristic_fastest(dag, time_m)\n",
        "    m_fast, c_fast = calculate_metrics(dag, alloc_dict_fastest, time_m, cost_m)\n",
        "    results['fastest_makespan'].append(m_fast)\n",
        "    results['fastest_cost'].append(c_fast)\n",
        "\n",
        "    # --- c. Avaliação da Heurística \"Cheapest\" ---\n",
        "    alloc_dict_cheapest = heuristic_cheapest(dag, cost_m)\n",
        "    m_cheap, c_cheap = calculate_metrics(dag, alloc_dict_cheapest, time_m, cost_m)\n",
        "    results['cheapest_makespan'].append(m_cheap)\n",
        "    results['cheapest_cost'].append(c_cheap)\n",
        "\n",
        "# --- 5. Comparar Resultados ---\n",
        "print(\"\\n--- Resultados da Avaliação (Média de 50 execuções) ---\")\n",
        "\n",
        "print(f\"\\nModelo GNN (Treinado para Makespan):\")\n",
        "print(f\"  - Makespan Médio: {np.mean(results['gnn_makespan']):.2f}\")\n",
        "print(f\"  - Custo Médio:    {np.mean(results['gnn_cost']):.2f}\")\n",
        "\n",
        "print(f\"\\nHeurística 'Mais Rápido':\")\n",
        "print(f\"  - Makespan Médio: {np.mean(results['fastest_makespan']):.2f}\")\n",
        "print(f\"  - Custo Médio:    {np.mean(results['fastest_cost']):.2f}\")\n",
        "\n",
        "print(f\"\\nHeurística 'Mais Barato':\")\n",
        "print(f\"  - Makespan Médio: {np.mean(results['cheapest_makespan']):.2f}\")\n",
        "print(f\"  - Custo Médio:    {np.mean(results['cheapest_cost']):.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpbpZ1fUTJqA"
      },
      "outputs": [],
      "source": [
        "# %%\n",
        "# ==============================================================================\n",
        "# CÉLULA 10: Conclusão e Próximos Passos\n",
        "# ==============================================================================\n",
        "#\n",
        "# Se o treinamento funcionou, você deve ver que o 'gnn_makespan' é\n",
        "# significativamente melhor (menor) que o 'cheapest_makespan' e\n",
        "# competitivo ou melhor que o 'fastest_makespan'.\n",
        "#\n",
        "# Isso ocorre porque a GNN aprendeu a otimizar o *makespan* (o caminho\n",
        "# crítico do DAG), enquanto a heurística \"Mais Rápido\" é ingênua e\n",
        "# apenas otimiza cada tarefa localmente, ignorando as dependências.\n",
        "#\n",
        "# Próximos Passos:\n",
        "# 1. Implementar a heurística GRASP-VND (que é um projeto por si só)\n",
        "#    e usá-la como um baseline muito mais forte.\n",
        "# 2. Experimentar com a função de perda na Célula 8 (W_TIME e W_COST)\n",
        "#    para encontrar alocações com diferentes trade-offs (Fronteira de Pareto).\n",
        "# 3. Aumentar o número de épocas e o tamanho dos dados de treinamento\n",
        "#    para obter melhores resultados.\n",
        "# 4. Testar a generalização (treinar em 15 tarefas, testar em 50).\n",
        "#"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
